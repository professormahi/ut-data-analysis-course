{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00: Getting Familiar with DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-olympics.json\t\t  04-derby.xlsx\r\n",
      "02-freeland-README.md\t\t  05-un-speech-README.md\r\n",
      "02-freeland.xlsx\t\t  05-un-speech.xlsx\r\n",
      "03-question-parliament-README.md  06-blue-girl.xlsx\r\n",
      "03-question-parliament.xlsx\t  07-bimar/\r\n",
      "04-derby-README.md\t\t  README.md\r\n"
     ]
    }
   ],
   "source": [
    "! ls -CF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00.json  01.json  02.json  03.json  04.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -CF data/07-bimar/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics = pd.read_json(\"data/01-olympics.json\", lines=True)\n",
    "free_land = pd.read_excel(\"data/02-freeland.xlsx\", engine='openpyxl')\n",
    "question_parliament = pd.read_excel(\"data/03-question-parliament.xlsx\", engine='openpyxl')\n",
    "derby = pd.read_excel(\"data/04-derby.xlsx\", engine='openpyxl')\n",
    "un_speech = pd.read_excel(\"data/05-un-speech.xlsx\", engine='openpyxl')\n",
    "blue_girl = pd.read_excel(\"data/06-blue-girl.xlsx\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimar = pd.concat([\n",
    "    pd.read_json(\"data/07-bimar/01.json\", lines=True),\n",
    "    pd.read_json(\"data/07-bimar/02.json\", lines=True),\n",
    "    pd.read_json(\"data/07-bimar/03.json\", lines=True),\n",
    "    pd.read_json(\"data/07-bimar/04.json\", lines=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_land = free_land.dropna(how='all')\n",
    "question_parliament = question_parliament.dropna(how='all')\n",
    "derby = derby.dropna(how='all')\n",
    "un_speech = un_speech.dropna(how='all')\n",
    "blue_girl = blue_girl.dropna(how='all')\n",
    "\n",
    "\n",
    "bimar = bimar.drop_duplicates(subset=['id'])  # Remove duplicate twitts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-f750ccff5099>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  _ = pd.DataFrame(np.array([\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Freeland</td>\n",
       "      <td>7,562</td>\n",
       "      <td>[Date, Screen Name, Full Name, Tweet Text, Twe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question Parliament</td>\n",
       "      <td>113,962</td>\n",
       "      <td>[Date, Screen Name, Full Name, Tweet Text, Twe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Derby</td>\n",
       "      <td>56,981</td>\n",
       "      <td>[Date, Screen Name, Full Name, Tweet Text, Twe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UN Speech</td>\n",
       "      <td>28,462</td>\n",
       "      <td>[Date, Screen Name, Full Name, Tweet Text, Twe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blue Girl</td>\n",
       "      <td>4,354,889</td>\n",
       "      <td>[extracted_hashtag, follower_count, following_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bimar</td>\n",
       "      <td>216,183</td>\n",
       "      <td>[created_at, id, id_str, text, source, truncat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Olympics</td>\n",
       "      <td>472,006</td>\n",
       "      <td>[created_at, id, id_str, text, source, truncat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DataSet       Rows  \\\n",
       "0             Freeland      7,562   \n",
       "1  Question Parliament    113,962   \n",
       "2                Derby     56,981   \n",
       "3            UN Speech     28,462   \n",
       "4            Blue Girl  4,354,889   \n",
       "5                Bimar    216,183   \n",
       "6             Olympics    472,006   \n",
       "\n",
       "                                             Columns  \n",
       "0  [Date, Screen Name, Full Name, Tweet Text, Twe...  \n",
       "1  [Date, Screen Name, Full Name, Tweet Text, Twe...  \n",
       "2  [Date, Screen Name, Full Name, Tweet Text, Twe...  \n",
       "3  [Date, Screen Name, Full Name, Tweet Text, Twe...  \n",
       "4  [extracted_hashtag, follower_count, following_...  \n",
       "5  [created_at, id, id_str, text, source, truncat...  \n",
       "6  [created_at, id, id_str, text, source, truncat...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = pd.DataFrame(np.array([\n",
    "    ['Freeland', free_land.size, free_land.columns.to_list()],\n",
    "    ['Question Parliament', question_parliament.size, question_parliament.columns.to_list()],\n",
    "    ['Derby', derby.size, derby.columns.to_list()],\n",
    "    ['UN Speech', un_speech.size, un_speech.columns.to_list()],\n",
    "    ['Blue Girl', blue_girl.size, blue_girl.columns.to_list()],\n",
    "    ['Bimar', bimar.size, bimar.columns.to_list()],\n",
    "    ['Olympics', olympics.size, olympics.columns.to_list()],\n",
    "]), columns=[\"DataSet\", \"Rows\", \"Columns\"], dtype=object)\n",
    "_.Rows = _.Rows.apply(lambda x : \"{:,}\".format(x))\n",
    "\n",
    "display(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference between Olympics and Bimar columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'id', 'id_str', 'text', 'source', 'truncated',\n",
       "       'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
       "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
       "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
       "       'contributors', 'is_quote_status', 'retweet_count', 'favorite_count',\n",
       "       'entities', 'favorited', 'retweeted', 'filter_level', 'lang',\n",
       "       'timestamp_ms', 'retweeted_status', 'display_text_range',\n",
       "       'extended_tweet', 'possibly_sensitive', 'extended_entities',\n",
       "       'quoted_status_id', 'quoted_status_id_str', 'quoted_status'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['display_text_range', 'extended_tweet']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(bimar.columns)\n",
    "list(set(bimar.columns.to_list()) - set(olympics.columns.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeland, Question Parliament, Derby and UN Speech have same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Screen Name', 'Full Name', 'Tweet Text', 'Tweet ID', 'Link(s)',\n",
       "       'Media', 'Location', 'App', 'Followers', 'Follows', 'Listed', 'Verfied',\n",
       "       'User Since', 'Location.1', 'Bio', 'Website', 'Timezone',\n",
       "       'Profile Image'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(free_land.columns)\n",
    "_[\"Columns\"][0] == _[\"Columns\"][1] == _[\"Columns\"][2] == _[\"Columns\"][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blue Girl Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['extracted_hashtag', 'follower_count', 'following_count', 'is_quote',\n",
       "       'lang', 'like_count', 'norm_description', 'post_count', 'time-date',\n",
       "       'time-time', 'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_girl.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Collections\n",
    "### 1. col1: Freeland, Question Parliament, Derby, UN Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = pd.concat([free_land, question_parliament, derby, un_speech])\n",
    "col1 = col1.drop_duplicates(subset=['Tweet ID'])  # Remove 200 duplicate tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add labels based on the data origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_lancers = free_land['Screen Name'].unique()\n",
    "soccer_lover = derby['Screen Name'].unique()\n",
    "political_enthusiast = pd.concat([question_parliament, un_speech])['Screen Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1.loc[col1['Screen Name'].isin(free_lancers), 'free lancer']=True\n",
    "col1.loc[col1['Screen Name'].isin(soccer_lover), 'soccer lover']=True\n",
    "col1.loc[col1['Screen Name'].isin(political_enthusiast), 'political enthusiast']=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickles/00-bimar.pkl\t pickles/00-free_land.pkl\r\n",
      "pickles/00-bluegirl.pkl  pickles/00-olympics.pkl\r\n",
      "pickles/00-col1.pkl\t pickles/00-question_parliament.pkl\r\n",
      "pickles/00-derby.pkl\t pickles/00-un_speech.pkl\r\n"
     ]
    }
   ],
   "source": [
    "prefix = \"00\"\n",
    "\n",
    "olympics.to_pickle(f'pickles/{prefix}-olympics.pkl')\n",
    "blue_girl.to_pickle(f'pickles/{prefix}-bluegirl.pkl')\n",
    "free_land.to_pickle(f'pickles/{prefix}-free_land.pkl')\n",
    "question_parliament.to_pickle(f'pickles/{prefix}-question_parliament.pkl')\n",
    "derby.to_pickle(f'pickles/{prefix}-derby.pkl')\n",
    "un_speech.to_pickle(f'pickles/{prefix}-un_speech.pkl')\n",
    "bimar.to_pickle(f'pickles/{prefix}-bimar.pkl')\n",
    "\n",
    "col1.to_pickle(f'pickles/{prefix}-col1.pkl')\n",
    "\n",
    "!ls pickles/00-*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
